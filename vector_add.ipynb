{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPCYmTTJ2HRdSzXp+RGqk9z"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%pip install triton"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GXLRjw1g4pNH",
        "outputId": "5fe534d9-5c92-4e7f-97b2-2e7c81de8598"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting triton\n",
            "  Downloading triton-3.6.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\n",
            "Downloading triton-3.6.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (188.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.3/188.3 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: triton\n",
            "Successfully installed triton-3.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "9ht1arEF4gHy"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "import triton\n",
        "import triton.language as tl"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DgqZpUzg5sN4",
        "outputId": "cea85146-66dd-4d58-b03d-d676374f2ef5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: nvidia-smi: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE = triton.runtime.driver.active.get_active_torch_device()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "Z5BJWFUC40fw",
        "outputId": "33d2dc84-fbdf-42e6-b614-c8e4442335e4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "0 active drivers ([]). There should only be one.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3325162982.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mDEVICE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtriton\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mruntime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_active_torch_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/triton/runtime/driver.py\u001b[0m in \u001b[0;36mactive\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mactive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mDriverBase\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_active\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_active\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_active\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/triton/runtime/driver.py\u001b[0m in \u001b[0;36mdefault\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mDriverBase\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_create_driver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/triton/runtime/driver.py\u001b[0m in \u001b[0;36m_create_driver\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mactive_drivers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdriver\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_active\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactive_drivers\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{len(active_drivers)} active drivers ({active_drivers}). There should only be one.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mactive_drivers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: 0 active drivers ([]). There should only be one."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@triton.jit\n",
        "def add_kernel(x_ptr,\n",
        "               y_ptr,\n",
        "               output_ptr,\n",
        "               n_elements,\n",
        "               BLOCK_SIZE: tl.constexpr):\n",
        "\n",
        "  pid = tl.program_id(axis=0) # this is like x.blockIdx * x.blockDim + x.threadIdx ?\n",
        "  block_start= pid * BLOCK_SIZE\n",
        "  offsets = block_start + tl.arange(0,BLOCK_SIZE)\n",
        "  # we create an entire guard array\n",
        "  mask = offsets < n_elements\n",
        "  x = tl.load(x_ptr + offsets,mask=mask)\n",
        "  y = tl.load(y_ptr + offsets,mask=mask)\n",
        "  output = x +y\n",
        "  tl.store(output_ptr + offsets, output, mask=mask)\n",
        "\n",
        "\n",
        "def add(x:torch.Tensor,y:torch.Tensor) -> torch.Tensor:\n",
        "\n",
        "  output = torch.empty_like(x)\n",
        "\n",
        "  assert x.device == DEVICE and y.device == DEVICE and output.device == DEVICE\n",
        "\n",
        "  n_elements = output.numel()\n",
        "  #cdiv gives ceiling division e.g int(n_elements / block_size) +1\n",
        "  grid = lambda meta: (triton.cdiv(n_elements,meta['BLOCK_SIZE']), )\n",
        "  add_kernel[grid](x,y,output,n_elements,BLOCK_SIZE=1024)\n",
        "  return output\n"
      ],
      "metadata": {
        "id": "iC6jwiS66TYH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(0)\n",
        "\n",
        "size = 76783\n",
        "\n",
        "x = torch.rand(size,device=DEVICE)\n",
        "y = torch.rand(size,device=DEVICE)\n",
        "\n",
        "output_torch = x + y\n",
        "output_triton = add(x,y)\n",
        "\n",
        "max(torch.abs(output_torch - output_triton))\n",
        "\n"
      ],
      "metadata": {
        "id": "LJs7eHKY9XCV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.element_size()"
      ],
      "metadata": {
        "id": "4_gZDKgSKhDI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@triton.testing.perf_report(\n",
        "    triton.testing.Benchmark(\n",
        "        x_names=['size'],\n",
        "        x_vals=[2**i for i in range (12,28,1)],\n",
        "        x_log = True,\n",
        "        line_arg ='provider',\n",
        "        line_vals = ['triton','torch'],\n",
        "        line_names = ['Triton','Torch'],\n",
        "        styles= [('blue','-'),('green','-')],\n",
        "        ylabel='GB/s',\n",
        "        plot_name='vector-add-performance',\n",
        "        args={}\n",
        "    )\n",
        ")\n",
        "def benchmark(size,provider):\n",
        "  x = torch.randn(size,device=DEVICE,dtype=torch.float32)\n",
        "  y = torch.randn(size,device=DEVICE,dtype=torch.float32)\n",
        "  quantiles=[0.5,0.2,0.8]\n",
        "  if provider=='torch':\n",
        "    ms,min_ms,max_ms = triton.testing.do_bench(lambda: x+y, quantiles=quantiles)\n",
        "  if provider=='triton':\n",
        "    ms,min_ms,max_ms = triton.testing.do_bench(lambda: add(x,y), quantiles=quantiles)\n",
        "  gbps = lambda ms: 3 * x.numel() * x.element_size() * 1e-9 / (ms* 1e-3)\n",
        "  return gbps(ms),gbps(max_ms),gbps(min_ms)\n",
        "\n",
        "benchmark.run(print_data=True,show_plots=True)"
      ],
      "metadata": {
        "id": "5crWTOVeItFv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}